---
title: "Literature review"
output: pdf_document
---

```{r,echo=FALSE, message=FALSE, results='hide', warning=FALSE}
# Loading libraries
require(ggplot2)
require(splitstackshape)
require(igraph)
require(knitr)

opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE)

# Set ggplot theme
theme_set(theme_minimal(12))
```

This report provides an analysis on the records downloaded from [Web of Science](http://webofscience.com). The analysis identifies the important authors, journals, and keywords in the dataset based on the number of occurences and citation counts. A citation network of the provided records is created and used to identify the important papers according to their in-degree, total citation count and PageRank scores. The analysis finds also often-cited references that were not included in the original dataset downloaded from the Web of Science.

Reports can be generated by using the [online analysis service](http://hammer.nailsproject.net/), and the source code is available at [GitHub](https://github.com/aknutas/nails). Instructions and links to tutorial videos can be found at the [project page](https://aknutas.github.io/nails/). For further details see the following article: [Knutas, A., Hajikhani, A., Salminen, J., Ikonen, J., Porras, J., 2015. Cloud-Based Bibliometric Analysis Service for Systematic Mapping Studies. CompSysTech 2015](http://www.codecamp.fi/lib/exe/fetch.php/wiki/nails-compsystech2015-preprint.pdf). Please cite our research paper on bibliometrics if you publish the analysis results. Use is otherwise free.

The analysed dataset consist of `r nrow(literature)` records with `r ncol(literature)` variables. More information about the variables can be found at [Web of Science](https://images.webofknowledge.com/WOK46/help/WOS/h_fullrec.html).

## Publication years
```{r, echo=FALSE, warning=FALSE, message=FALSE}
plot_year_abs(literature, input$yearBins)
```

## Relative publication volume
```{r, echo=FALSE}
plot_year_rel(literature)
```


## Important authors
Sorted by the number of articles published and by the total number of citations.
```{r,echo=FALSE}
plot_authors_prod(authors, input$nAuthors)
```

```{r,echo=FALSE}
plot_authors_cited(authors, input$nAuthors)
```

## Important publications
Sorted by number of published articles in the dataset and by the total number of citations.
```{r,echo=FALSE}
plot_publications_pop(publications, input$nPubs)
```

```{r,echo=FALSE}
plot_publications_cited(publications, input$nPubs)
```

## Important keywords
Sorted by the number of articles where the keyword is mentioned and by the total number of citations for the keyword.
```{r, echo=FALSE}
plot_keywords_pop(keywords, input$nKeywords)
```

```{r,echo=FALSE}
plot_keywords_cited(keywords, input$nKeywords)
```

## Important papers
The most important papers and other sources are identified below using three importance measures: 1) in-degree in the citation network, 2) citation count provided by Web of Science (only for papers included in the dataset), and 3) PageRank score in the citation network. The top 25 highest scoring papers are identified using these measures separately. The results are then combined and duplicates are removed. Results are sorted by in-degree, and ties are first broken by citation count and then by the PageRank.

When a [Digital Object Identifier (DOI)](http://www.doi.org/) is available, the full paper can be found using [Resolve DOI](https://dx.doi.org/) website.

### Included in the dataset
These papers were included in the `r nrow(literature)` records downloaded from the Web of Science.
```{r, echo=FALSE}
kable(create_lit_table(citationsLit, input$sortPapers, input$nPapers))
```

### Not included in the dataset
These papers and other references were not among the `r nrow(literature)` records downloaded from the Web of Science.
```{r, echo=FALSE}
kable(create_ref_table(citationsRef, input$sortPapers, input$nPapers))
```

```{r, results='asis', echo=FALSE}
cat('### Topic modeling output
[Topic modeling](https://en.wikipedia.org/wiki/Topic_model) is a type of statistical text mining method for discovering common "topics" that occur in a collection of documents. A topic modeling algorithm essentially looks through the abstracts included in the datasets for clusters of co-occurring of words and groups them together by a process of similarity.

The following columns describe each topic detected using [LDA topic modeling](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/) by listing the ten most characteristic words in each topic. See also the [interactive visualization](output/topicmodelvis/index.html) for a better characterization of the topics and a visual representation of how (dis)similar the detected topics are to each other.
')
```

```{r, echo=FALSE}
kable(TopicModelR()$topwords)
```

